.. _5-project_configuration:

Project Configuration
=====================

GinJinn2 projects are configured using files in `YAML <https://en.wikipedia.org/wiki/YAML>`_ format.
Each GinJinn2 project (folder) must contain this ``ginjinn_config.yaml`` file.
A project configuration file for a project generated by ``ginjinn new`` might look like this:

.. code-block:: YAML

    project_dir: "/home/ginjinn_user/my_project"
    task: "bbox-detection"
    # Input data options
    input:
        type: "COCO" # or "PVOC"
        training:
            annotation_path: "/home/ginjinn_user/my_dataset/train/annotations.json"
            image_path: "/home/ginjinn_user/my_dataset/train/images"
        validation:
            annotation_path: "/home/ginjinn_user/my_dataset/val/annotations.json"
            image_path: "/home/ginjinn_user/my_dataset/val/images"
        test:
            annotation_path: "/home/ginjinn_user/my_dataset/val/annotations.json"
            image_path: "/home/ginjinn_user/my_dataset/val/images"

    # Model options
    model:
        name: "faster_rcnn_R_50_FPN_1x"
        weights: "pretrained"

        # additional model options
        model_parameters:
            # anchor generator options
            anchor_generator:
                aspect_ratios:
                    - - 0.5
                      - 1.0
                      - 2.0

    # Options for model training
    training:
        learning_rate: 0.00125
        batch_size: 1
        max_iter: 5000
        eval_period: 250
        checkpoint_period: 2500

    # Options for image augmentation
    augmentation:
        - horizontal_flip:
            probability: 0.25

    # Additional options
    options:
        n_threads: 1
    

The following sections will describe each part of the config file in detail.

General Configuration
---------------------

The general configuration comprises the project directory and the model task (i.e. bounding-box detection or intance segmentation).
Both entry will automatically be set when the project is generated using ``ginjinn new``.

``project_dir``
^^^^^^^^^^^^^^^
Absolute path to the project directory.
If the project is moved to another disk location, this configuration must be updated to the new location.

Example:

.. code-block:: YAML

    project_dir: "/home/ginjinn_user/my_project"

``task``
^^^^^^^^^
Project task.
Either "bbox-detection" or "instance-segmentation" for bounding-box detection and instance segmentation, respectively.

Example:

.. code-block:: YAML

    task: "instance-segmentation"

``input`` Configuration
-----------------------

The input entry comprises the configuration describing input type and locations of training, and optionally (but highly recommended) validation and test datasets. 
This entry will be automatically set, when generating the project using ``ginjinn new`` with the ``-d`` option.

Example:

.. code-block:: YAML

    input:
        type: "COCO"
        training:
            ...
        ...


``type``
^^^^^^^^

Dataset type.
Either "COCO" or "PVOC" for COCO and PASCAL VOC datasets, respectively.
See :doc:`Overview <2-overview>` for a brief description of the dataset types.
We recommend working with COCO datasets whenever possible.

Example:

.. code-block:: YAML

    type: "COCO"


``training``, ``validation``, ``test``
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Paths to training, validation, and test datasets.
Each entry comprises an ``annotation_path`` and an ``image_path`` field, determining the location of the annotations and images on disk, respectively.
Only the entry ``training`` is required, but we strongly suggest to supply at the very least one of validation and test datasets.
A training-validation-test split can be generated using ``ginjinn split``.

Example:

.. code-block:: YAML

    training:
        annotation_path: "/home/ginjinn_user/my_dataset/train/annotations.json"
        image_path: "/home/ginjinn_user/my_dataset/train/images"
    validation:
        annotation_path: "/home/ginjinn_user/my_dataset/val/annotations.json"
        image_path: "/home/ginjinn_user/my_dataset/val/images"

``training`` Configuration
--------------------------

This entry determines several configurations considering the model training, including, for example, the number of trianing iterations and the evaluation period.

Example:

.. code-block:: YAML

    training:
        max_iter: 1000
        eval_period: 250
        ...


``max_iter``
^^^^^^^^^^^^

Number of training iterations.

Example:

.. code-block:: YAML

        max_iter: 2500


``eval_period``
^^^^^^^^^^^^^^^

Number of training iterations between valiation dataset evaluations.
A value of 250, for example, means that after every 250 training iterations the whole validation dataset will be evaluated and the evaluation results will be written to ``mertics.json``, ``metrics.pdf``, and ``events.out.*``.
Setting a low value (high frequency of evaluations) might be computationally costly, depending on the size of the validation dataset.

Example:

.. code-block:: YAML

    eval_period: 500


``checkpoint_period``
^^^^^^^^^^^^^^^^^^^^^

Number of training iterations between saving model checkpoints.
A value of 500, for example, means that after every 500 training iterations the model weights will be saved to "model\_*.pth" files.
Checkpoints are useful, if the model was trained too long, leading to overfitting (see `Early Stopping <https://en.wikipedia.org/wiki/Early_stopping>`_).
Note: a model checkpoint is typically several hundred megabyte in size, hence setting this value too low might lead to storage issues.

Example:

.. code-block:: YAML

    checkpoint_period: 1000


``batch_size``
^^^^^^^^^^^^^^

The number of images to process per interation at once.
Depending on your GPU memory, you might want to set this a value > 1.
When changing the batch size, it might also be advisible to adapt ``learning_rate`` accordingly.

Example:

.. code-block:: YAML

    batch_size: 2


``learning_rate``
^^^^^^^^^^^^^^^^^

A factor determining how strongly the model weights are adjusted per iteration.
A high value might cause the model to diverge, while a very low value might lead to slow learning.
The default values should already be sensible for the provided models.
If the ``batch_size`` is changed, however, the ``learning_rate`` should be adjusted proportionally.
For example, if ``batch_size`` is set to 4, the ``learning_rate`` should be multiplied by 4.

Example:

.. code-block:: YAML

    learning_rate: 0.00125


``warmup_iter``
^^^^^^^^^^^^^^^

Number of iterations until ``learning_rate`` is reached.
The model training starts with a learning rate value of ``learning_rate``/``warmup_iter``, which increases up to ``learning_rate`` after ``warmup_iter`` iterations.
This can counter an early divergence of the model when using random weight initialization.
Typically, this value does not need to be changed.

Example:

.. code-block:: YAML

    warmup_iter: 1000


.. ``momentum``
.. ^^^^^^^^^^^^^^^

.. Momentum parameter for the Stochastic Gradient Descent

``model`` Configuration
-----------------------


``augmentation`` Configuration
------------------------------


``options`` Configuration
-------------------------


Bounding-Box Detection Models
-----------------------------

Faster R-CNN
^^^^^^^^^^^^



Instance Segmentation Models
----------------------------

Mask R-CNN
^^^^^^^^^^


Detectron2 Configuration
------------------------

